name: Daily Database Backup (API Method)

on:
  schedule:
    # Run daily at 2 AM CST (8 AM UTC)
    - cron: '0 8 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Create backup directory
        run: |
          mkdir -p backups
          echo "BACKUP_DATE=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_ENV
      
      - name: Install dependencies
        run: |
          npm install @supabase/supabase-js
      
      - name: Create backup script
        run: |
          cat > backup-script.mjs << 'EOF'
          import { createClient } from '@supabase/supabase-js';
          import fs from 'fs';

          async function backupDatabase() {
            const supabase = createClient(
              process.env.SUPABASE_URL,
              process.env.SUPABASE_SERVICE_KEY
            );

            const startTime = Date.now();
            console.log('Fetching all tables data...');
            
            const tables = [
              'prayers',
              'prayer_updates',
              'prayer_prompts',
              'prayer_types',
              'email_subscribers',
              'user_preferences',
              'status_change_requests',
              'update_deletion_requests',
              'admin_settings',
              'analytics'
            ];

            const backup = {
              timestamp: new Date().toISOString(),
              version: '1.0',
              tables: {}
            };

            for (const table of tables) {
              try {
                console.log(`Backing up table: ${table}...`);
                const { data, error } = await supabase
                  .from(table)
                  .select('*');
                
                if (error && error.code !== 'PGRST116') {
                  console.error(`Error backing up ${table}:`, error);
                  backup.tables[table] = { error: error.message, data: [] };
                } else {
                  backup.tables[table] = { count: data?.length || 0, data: data || [] };
                  console.log(`✓ Backed up ${data?.length || 0} rows from ${table}`);
                }
              } catch (err) {
                console.error(`Exception backing up ${table}:`, err);
                backup.tables[table] = { error: err.message, data: [] };
              }
            }

            // Save backup as JSON
            const filename = `backups/backup_${process.env.BACKUP_DATE}.json`;
            fs.writeFileSync(filename, JSON.stringify(backup, null, 2));
            console.log(`\n✓ Backup saved to ${filename}`);

            // Calculate duration
            const endTime = Date.now();
            const durationSeconds = Math.round((endTime - startTime) / 1000);

            // Create summary
            const summary = {
              timestamp: backup.timestamp,
              date: process.env.BACKUP_DATE,
              type: 'api',
              format: 'json',
              tables: Object.keys(backup.tables).reduce((acc, table) => {
                acc[table] = backup.tables[table].count || 0;
                return acc;
              }, {})
            };

            fs.writeFileSync(
              `backups/backup_${process.env.BACKUP_DATE}_summary.json`,
              JSON.stringify(summary, null, 2)
            );

            console.log('\nBackup Summary:');
            console.log(JSON.stringify(summary, null, 2));

            // Log backup to database (keeps free tier active)
            const totalRecords = Object.values(summary.tables).reduce((sum, count) => sum + count, 0);
            
            try {
              const { error: logError } = await supabase
                .from('backup_logs')
                .insert({
                  backup_date: new Date().toISOString(),
                  status: 'success',
                  tables_backed_up: summary.tables,
                  total_records: totalRecords,
                  duration_seconds: durationSeconds
                });

              if (logError) {
                console.error('Warning: Failed to log backup to database:', logError);
              } else {
                console.log('✓ Backup logged to database');
              }
            } catch (logErr) {
              console.error('Warning: Exception logging backup:', logErr);
            }
          }

          backupDatabase().catch(async err => {
            console.error('Backup failed:', err);
            
            // Try to log the failure
            try {
              const supabase = createClient(
                process.env.SUPABASE_URL,
                process.env.SUPABASE_SERVICE_KEY
              );
              
              await supabase.from('backup_logs').insert({
                backup_date: new Date().toISOString(),
                status: 'failed',
                error_message: err.message || String(err),
                total_records: 0
              });
            } catch (logErr) {
              console.error('Could not log failure:', logErr);
            }
            
            process.exit(1);
          });
          EOF
      
      - name: Run backup
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          BACKUP_DATE: ${{ env.BACKUP_DATE }}
        run: |
          node backup-script.mjs
      
      - name: Compress backup
        run: |
          cd backups
          gzip backup_${BACKUP_DATE}.json
          echo "✓ Backup compressed"
      
      - name: Upload backup as artifact
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-${{ env.BACKUP_DATE }}
          path: backups/backup_${{ env.BACKUP_DATE }}.json.gz
          retention-days: 30
